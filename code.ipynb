{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzKAKnicXEcT",
        "outputId": "ab806f2e-9967-4586-cad5-a8570f5247d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Change path according to your folder name in Google Drive\n",
        "project_path = '/content/drive/MyDrive/student_resource'\n",
        "\n",
        "# Change directory to that path\n",
        "os.chdir(project_path)\n",
        "\n",
        "# Confirm\n",
        "print(\"Current working directory:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoWfo8PLXciX",
        "outputId": "6ddbc4bb-b680-4ab9-df07-131da27f4605"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content/drive/MyDrive/student_resource\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHkdo3BMXgBy",
        "outputId": "a3ae2662-d9f4-4d13-814d-715037a35292"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_test.csv  sample_test_out.csv  test.csv\ttrain.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Import libraries\n",
        "\n",
        "import pandas as pd   # For data handling\n",
        "import numpy as np    # For numerical operations\n",
        "import matplotlib.pyplot as plt   # For plotting graphs\n",
        "import seaborn as sns  # For advanced visualizations\n",
        "\n",
        "# FIX: use seaborn‚Äôs theme directly instead of matplotlib style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "print(\"Libraries imported¬†successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QnaaK3AXjBn",
        "outputId": "05d31bc8-e91b-4794-948a-0a0ce5765cef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported¬†successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Load train and test datasets\n",
        "\n",
        "train_df = pd.read_csv(\"dataset/train.csv\")\n",
        "test_df = pd.read_csv(\"dataset/test.csv\")\n",
        "\n",
        "# Check their shapes\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape:\", test_df.shape)\n",
        "\n",
        "# Display first 5 rows\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "Arbs4diQXoS8",
        "outputId": "c36b0095-2083-4173-b5fd-ffa1c2b65728"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (75000, 4)\n",
            "Test shape: (75000, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sample_id                                    catalog_content  \\\n",
              "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
              "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
              "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
              "3      55858  Item Name: Judee‚Äôs Blue Cheese Powder 11.25 oz...   \n",
              "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
              "\n",
              "                                          image_link  price  \n",
              "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89  \n",
              "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12  \n",
              "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97  \n",
              "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34  \n",
              "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c128b7ef-cfc1-47f9-9245-9b2ecea4d7c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>catalog_content</th>\n",
              "      <th>image_link</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33127</td>\n",
              "      <td>Item Name: La Victoria Green Taco Sauce Mild, ...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/51mo8htwTH...</td>\n",
              "      <td>4.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198967</td>\n",
              "      <td>Item Name: Salerno Cookies, The Original Butte...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/71YtriIHAA...</td>\n",
              "      <td>13.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>261251</td>\n",
              "      <td>Item Name: Bear Creek Hearty Soup Bowl, Creamy...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-...</td>\n",
              "      <td>1.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55858</td>\n",
              "      <td>Item Name: Judee‚Äôs Blue Cheese Powder 11.25 oz...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/41mu0HAToD...</td>\n",
              "      <td>30.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>292686</td>\n",
              "      <td>Item Name: kedem Sherry Cooking Wine, 12.7 Oun...</td>\n",
              "      <td>https://m.media-amazon.com/images/I/41sA037+Qv...</td>\n",
              "      <td>66.49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c128b7ef-cfc1-47f9-9245-9b2ecea4d7c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c128b7ef-cfc1-47f9-9245-9b2ecea4d7c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c128b7ef-cfc1-47f9-9245-9b2ecea4d7c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d957acd5-c5ab-47d0-b373-4a6f349131a3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d957acd5-c5ab-47d0-b373-4a6f349131a3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d957acd5-c5ab-47d0-b373-4a6f349131a3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 75000,\n  \"fields\": [\n    {\n      \"column\": \"sample_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86585,\n        \"min\": 0,\n        \"max\": 299438,\n        \"num_unique_values\": 75000,\n        \"samples\": [\n          158784,\n          4095,\n          172021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"catalog_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74900,\n        \"samples\": [\n          \"Item Name: Cooper Street Granola Bakes - Chewy Breakfast Granola Bars with Chia, Flax, Buckwheat and Oats - Blueberry Pomegranate Individually Wrapped Nut & Dairy Free On-The-Go or School Snacks - 12 Bars, 1oz each\\nBullet Point 1: Cookies, Made Better - Fuel your day and enjoy delectably chewy goodness with Cooper Street Granola Bars Bulk! Bite into wholesome and healthful ingredients like chia, flax, buckwheat and oats and get off on the right foot with our healthy snack bars!\\nBullet Point 2: Blueberry Pomegranate Flavor - Bursting with locally sourced Michigan blueberries and blended with a pomegranate's pop, our granola snack bars deliver the perfect mix of sweet and tart. Pomegranates and blueberries truly are a match made in heaven!\\nBullet Point 3: Guilt-Free Deliciousness - Start your day on a high note with the energy you need with this pomegranate blueberry bar. Our satiating anytime breakfast cookies individually wrapped satisfy your sweet tooth with high-quality ingredients, for a truly clean and honest energy boost throughout your day!\\nBullet Point 4: Baked With Care - Made with a mix of passion, all natural ingredients and 100 years of tradition, our healthy granola bar is still handmade in our family-run Michigan bakery. Our perfect pick me up is baked to a moist and chewy perfection.\\nBullet Point 5: Enjoyed By All - We go the extra mile to ensure everyone can enjoy our granola soft baked cookies. Made in a dedicated peanut free facility to be dairy free, HFCS free, tans fat free, soy free, artificial flavourings free and also low in sodium. We don't tolerate any nasties!\\nProduct Description: individual snacks breakfast foods individually wrapped breakfast food breakfast snacks individually wrapped granola snacks individual packs healthy bars for kids bars healthy granola bars for kids granola bars kids bars kids granola bars healthy organic kids snacks kids granola bars kids bar organic granola bars snack bars for kids kid bars healthy snacks for kids granola bars variety packs breakfast bars healthy snack bars healthy food bars nut free bars granola bars soft grabola bars granila bars grnola bars granola bara gronala bars gronalla bars individually wrapped breakfast items good snacks for kids granola bar packs kids breakfast bars healthy snacks for kids individually wrapped bars food copper street blueberry pomegranate cookie cooper street cookie blueberry pomegranate cooper street blueberry pomegrante pomegranate blueberry bar cooper street blueberry pomegranate granola cookie bakes cooper street cookies blueberry pomegranate bakes blurberry pomegranit granola cooper street pomegranate blueberry pomogranite granola bake blueberry pomogranate bars blueberry pomegranate granola cookie blueberry and pomegranate granola bar cooper st blueberry pomegranite granola bar cooper st blueberry pomegrante bars blueberry pomegrenate cooper street cooper street blueberry pomegranite cooper street blueberry pomegrante bar copper street granola bar - blueberry pomegranate blueberry pomegranate granola cookie bake blueberry pomegranate granola bakes 12-count (1 oz or 2 oz) pomegranate blueberry snack cooper street snacks blueberry pom cooper street cookies chewy granola bakes blueberry pomegranate 1... cooper farms blueberry pomegranate bars blueberry pomegranate granola bakes blueberry pomegranate granola bars blueberry pomegranate granola bar pomegranate pomegranate snacks 1 ounce - 12 per case cooper street granola cookie bakes blueberry pomegranate blueberry pomegranate bar blueberry pomegranate bars cooper street blueberry pomegranate granola cookie bake\\nValue: 12.0\\nUnit: Ounce\\n\",\n          \"Item Name: Stonewall Kitchen Wildflower Honey, 16 Ounces\\nBullet Point 1: Stonewall Kitchen Wildflower Honey, 16 Ounces\\nBullet Point 2: Our Wildflower Honey is a delicious and unique blend of nectars gathered from a variety of flowering trees, shrubs and flowers\\nBullet Point 3: A delectably sweet, medium flavored honey with floral notes\\nBullet Point 4: Perfect for sweetening tea, enjoying on pancakes or for adding wonderful flavor to baked goods\\nBullet Point 5: Stonewall Kitchen Family of Brands: Our award winning line of gourmet food, home goods, and gifts are loved around the world. Featuring brands such as Legal Sea Foods, Michel Design Works, Montebello, Napa Valley Naturals, Stonewall Home, Stonewall Kitchen, Urban Accents, Vermont Coffee Company, Vermont Village, and Village Candle\\nBullet Point 6: About Us: It all started in 1991 at a local farmers' market with a few dozen items that we'd finished hand-labeling only hours before. Fast-forward to today and Stonewall Kitchen is now home to an ever-growing family of like-minded lifestyle brands! Expertly made with premium ingredients, our products are the result of decades spent dreaming up, testing and producing only the very best in specialty foods and fine home living.\\nValue: 16.0\\nUnit: Ounce\\n\",\n          \"Item Name: Quaker Large Rice Cakes, Lightly Salted, Pack of 6\\nBullet Point 1: Made with whole grain brown rice and baked to crispy deliciousness\\nBullet Point 2: Enjoy plain or top with your own peanut butter, jelly, or jam. Great for any snacking occasion\\nBullet Point 3: 35 calories per cake\\nBullet Point 4: The perfect amount of crunch, with the taste of salt\\nValue: 26.82\\nUnit: Ounce\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 72288,\n        \"samples\": [\n          \"https://m.media-amazon.com/images/I/81x1QmnBG-L.jpg\",\n          \"https://m.media-amazon.com/images/I/81MWCBM09NL.jpg\",\n          \"https://m.media-amazon.com/images/I/91X0Abm9cGL.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.37693218315522,\n        \"min\": 0.13,\n        \"max\": 2796.0,\n        \"num_unique_values\": 11862,\n        \"samples\": [\n          22.075,\n          15.69,\n          55.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/student_resource/src')  # Add the folder containing utils.py to Python path\n",
        "\n",
        "from utils import download_images, download_image"
      ],
      "metadata": {
        "id": "O4RsFDJAX2pK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load train embeddings if saved\n",
        "train_text_embeddings = np.load('/content/drive/MyDrive/student_resource/embeddings/train_text_embeddings_75k.npy')\n",
        "train_image_embeddings = np.load('/content/drive/MyDrive/student_resource/embeddings/train_image_embeddings_75k.npy')\n",
        "\n",
        "# Extra features\n",
        "train_df['text_len'] = train_df['catalog_content'].apply(len)\n",
        "train_df['num_words'] = train_df['catalog_content'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Combine all features\n",
        "X = np.concatenate([\n",
        "    train_text_embeddings,\n",
        "    train_image_embeddings,\n",
        "    train_df[['text_len','num_words']].values\n",
        "], axis=1)\n",
        "\n",
        "y = np.log1p(train_df['price'].values)  # log-transform for stability\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6W56lpKY8xh",
        "outputId": "3272b52c-aecf-4d88-e217-3e6eb3618b45"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (75000, 1026)\n",
            "y shape: (75000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSuaubYBaBcI",
        "outputId": "a1135ee5-c8b1-465f-f063-3e3745e33b5f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# GPU-Optimized Ensemble Training (1 Fold Each)\n",
        "# LightGBM + XGBoost + CatBoost\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "\n",
        "# -----------------------------\n",
        "# Detect device\n",
        "# -----------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Prepare train/test split (1 fold)\n",
        "# -----------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}\")\n",
        "\n",
        "# ============================================================\n",
        "# ‚ø° LightGBM\n",
        "# ============================================================\n",
        "print(\"\\nüü¢ Training LightGBM...\")\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "lgb_val = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': 31,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'seed': 42,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Enable GPU if available\n",
        "if device == \"cuda\":\n",
        "    lgb_params['device'] = 'gpu'\n",
        "    lgb_params['gpu_platform_id'] = 0\n",
        "    lgb_params['gpu_device_id'] = 0\n",
        "    print(\"‚úÖ Using GPU for LightGBM\")\n",
        "\n",
        "lgb_model = lgb.train(\n",
        "    lgb_params,\n",
        "    lgb_train,\n",
        "    valid_sets=[lgb_train, lgb_val],\n",
        "    num_boost_round=1000,\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=50),\n",
        "               lgb.log_evaluation(100)]\n",
        ")\n",
        "print(\"‚úÖ LightGBM done!\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ‚ø¢ XGBoost\n",
        "# ============================================================\n",
        "print(\"\\nüîµ Training XGBoost...\")\n",
        "\n",
        "xgb_params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'rmse',\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "# Enable GPU if available\n",
        "if device == \"cuda\":\n",
        "    xgb_params['tree_method'] = 'gpu_hist'\n",
        "    print(\"‚úÖ Using GPU for XGBoost\")\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "xgb_model = xgb.train(\n",
        "    params=xgb_params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=1000,\n",
        "    evals=[(dtrain, \"train\"), (dval, \"val\")],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=100\n",
        ")\n",
        "print(\"‚úÖ XGBoost done!\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ‚ø£ CatBoost\n",
        "# ============================================================\n",
        "print(\"\\nüü£ Training CatBoost...\")\n",
        "\n",
        "cat_params = {\n",
        "    'iterations': 1000,\n",
        "    'learning_rate': 0.05,\n",
        "    'depth': 8,\n",
        "    'loss_function': 'RMSE',\n",
        "    'eval_metric': 'RMSE',\n",
        "    'random_seed': 42,\n",
        "    'task_type': 'GPU' if device == \"cuda\" else 'CPU',\n",
        "    'verbose': 100\n",
        "}\n",
        "\n",
        "cat_model = CatBoostRegressor(**cat_params)\n",
        "cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
        "print(\"‚úÖ CatBoost done!\")\n",
        "\n",
        "# ============================================================\n",
        "# Save models for later ensembling\n",
        "# ============================================================\n",
        "import joblib\n",
        "joblib.dump(lgb_model, \"/content/lgb_model_gpu.pkl\")\n",
        "joblib.dump(xgb_model, \"/content/xgb_model_gpu.pkl\")\n",
        "cat_model.save_model(\"/content/cat_model_gpu.cbm\")\n",
        "\n",
        "print(\"\\nüéâ All models trained and saved¬†successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNiCEyn8aGKX",
        "outputId": "c8fd261a-afc4-401e-b5db-6cae803b4fa9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Train shape: (60000, 1026), Val shape: (15000, 1026)\n",
            "\n",
            "üü¢ Training LightGBM...\n",
            "‚úÖ Using GPU for LightGBM\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\ttraining's rmse: 0.740431\tvalid_1's rmse: 0.79061\n",
            "[200]\ttraining's rmse: 0.685735\tvalid_1's rmse: 0.767987\n",
            "[300]\ttraining's rmse: 0.644815\tvalid_1's rmse: 0.756805\n",
            "[400]\ttraining's rmse: 0.610353\tvalid_1's rmse: 0.749728\n",
            "[500]\ttraining's rmse: 0.580497\tvalid_1's rmse: 0.744975\n",
            "[600]\ttraining's rmse: 0.553418\tvalid_1's rmse: 0.741437\n",
            "[700]\ttraining's rmse: 0.528894\tvalid_1's rmse: 0.73871\n",
            "[800]\ttraining's rmse: 0.506197\tvalid_1's rmse: 0.735861\n",
            "[900]\ttraining's rmse: 0.485292\tvalid_1's rmse: 0.734194\n",
            "[1000]\ttraining's rmse: 0.465084\tvalid_1's rmse: 0.732531\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's rmse: 0.465084\tvalid_1's rmse: 0.732531\n",
            "‚úÖ LightGBM done!\n",
            "\n",
            "üîµ Training XGBoost...\n",
            "‚úÖ Using GPU for XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [16:36:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-rmse:0.92719\tval-rmse:0.94189\n",
            "[100]\ttrain-rmse:0.57729\tval-rmse:0.76813\n",
            "[200]\ttrain-rmse:0.45752\tval-rmse:0.75093\n",
            "[300]\ttrain-rmse:0.37633\tval-rmse:0.74253\n",
            "[400]\ttrain-rmse:0.31498\tval-rmse:0.73699\n",
            "[500]\ttrain-rmse:0.26745\tval-rmse:0.73360\n",
            "[600]\ttrain-rmse:0.22606\tval-rmse:0.73075\n",
            "[700]\ttrain-rmse:0.19464\tval-rmse:0.72917\n",
            "[800]\ttrain-rmse:0.16756\tval-rmse:0.72777\n",
            "[900]\ttrain-rmse:0.14514\tval-rmse:0.72673\n",
            "[999]\ttrain-rmse:0.12671\tval-rmse:0.72594\n",
            "‚úÖ XGBoost done!\n",
            "\n",
            "üü£ Training CatBoost...\n",
            "0:\tlearn: 0.9308914\ttest: 0.9438483\tbest: 0.9438483 (0)\ttotal: 88.5ms\tremaining: 1m 28s\n",
            "100:\tlearn: 0.7691850\ttest: 0.8069969\tbest: 0.8069969 (100)\ttotal: 4.03s\tremaining: 35.9s\n",
            "200:\tlearn: 0.7315073\ttest: 0.7888679\tbest: 0.7888679 (200)\ttotal: 8.97s\tremaining: 35.6s\n",
            "300:\tlearn: 0.7023356\ttest: 0.7780510\tbest: 0.7780510 (300)\ttotal: 12.6s\tremaining: 29.4s\n",
            "400:\tlearn: 0.6774354\ttest: 0.7705950\tbest: 0.7705950 (400)\ttotal: 16.3s\tremaining: 24.3s\n",
            "500:\tlearn: 0.6552311\ttest: 0.7652638\tbest: 0.7652638 (500)\ttotal: 21s\tremaining: 20.9s\n",
            "600:\tlearn: 0.6354373\ttest: 0.7606425\tbest: 0.7606425 (600)\ttotal: 24.6s\tremaining: 16.3s\n",
            "700:\tlearn: 0.6172882\ttest: 0.7571342\tbest: 0.7571342 (700)\ttotal: 28.1s\tremaining: 12s\n",
            "800:\tlearn: 0.5999022\ttest: 0.7537828\tbest: 0.7537828 (800)\ttotal: 32.2s\tremaining: 8.01s\n",
            "900:\tlearn: 0.5834572\ttest: 0.7511688\tbest: 0.7511688 (900)\ttotal: 36.5s\tremaining: 4.01s\n",
            "999:\tlearn: 0.5680390\ttest: 0.7484900\tbest: 0.7484900 (999)\ttotal: 40s\tremaining: 0us\n",
            "bestTest = 0.7484899729\n",
            "bestIteration = 999\n",
            "‚úÖ CatBoost done!\n",
            "\n",
            "üéâ All models trained and saved¬†successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.12/pickle.py:576: UserWarning: [16:39:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  rv = reduce(self.proto)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save models\n",
        "joblib.dump(lgb_model, \"lgb_model.pkl\")\n",
        "# joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
        "# joblib.dump(cat_model, \"cat_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hYZDLGUe_Jm",
        "outputId": "d63483d9-9361-470c-d951-15d4fbff20d1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lgb_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save models\n",
        "joblib.dump(lgb_model, \"lgb_model.pkl\")\n",
        "# joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
        "# joblib.dump(cat_model, \"cat_model.pkl\")"
      ],
      "metadata": {
        "id": "-b232h6ofDx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train)\n",
        "dval = xgb.DMatrix(X_val)\n",
        "\n",
        "train_pred_xgb = xgb_model.predict(dtrain)\n",
        "val_pred_xgb   = xgb_model.predict(dval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZrtzAQ5fvZ2",
        "outputId": "9d517d59-8d5f-4895-c449-34a9a42a6467"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [16:54:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# ====================================================\n",
        "# Load trained base models\n",
        "# ====================================================\n",
        "lgb_model = joblib.load(\"lgb_model.pkl\")\n",
        "xgb_model = joblib.load(\"xgb_model.pkl\")\n",
        "cat_model = joblib.load(\"cat_model.pkl\")\n",
        "\n",
        "# ====================================================\n",
        "# Generate out-of-fold predictions for stacking\n",
        "# ====================================================\n",
        "print(\"üîπ Generating meta-features (level-1 predictions)...\")\n",
        "\n",
        "train_pred_lgb = lgb_model.predict(X_train)\n",
        "val_pred_lgb = lgb_model.predict(X_val)\n",
        "\n",
        "train_pred_xgb = xgb_model.predict(X_train)\n",
        "val_pred_xgb = xgb_model.predict(X_val)\n",
        "\n",
        "train_pred_cat = cat_model.predict(X_train)\n",
        "val_pred_cat = cat_model.predict(X_val)\n",
        "\n",
        "# Stack predictions horizontally ‚Üí meta-features\n",
        "X_train_meta = np.column_stack((train_pred_lgb, train_pred_xgb, train_pred_cat))\n",
        "X_val_meta = np.column_stack((val_pred_lgb, val_pred_xgb, val_pred_cat))\n",
        "\n",
        "# ====================================================\n",
        "# Train meta-learner (Ridge Regression with CV)\n",
        "# ====================================================\n",
        "print(\"üîπ Training meta-learner (RidgeCV)...\")\n",
        "\n",
        "meta_model = RidgeCV(alphas=np.logspace(-3, 3, 7), cv=5)\n",
        "meta_model.fit(X_train_meta, y_train)\n",
        "\n",
        "# ====================================================\n",
        "# Evaluate stacking performance\n",
        "# ====================================================\n",
        "val_meta_pred = meta_model.predict(X_val_meta)\n",
        "stack_rmse = mean_squared_error(y_val, val_meta_pred, squared=False)\n",
        "\n",
        "print(f\"‚úÖ Stacking Ensemble RMSE: {stack_rmse:.6f}\")\n",
        "\n",
        "# ====================================================\n",
        "# Save final stacked model\n",
        "# ====================================================\n",
        "joblib.dump(meta_model, \"stacked_model.pkl\")\n",
        "print(\"üéØ Final stacked model saved as 'stacked_model.pkl'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "WCkRnzNrgHUA",
        "outputId": "074710e7-ec12-445d-bcd5-368efc15be3c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Generating meta-features (level-1 predictions)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2252598777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mval_pred_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_pred_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mval_pred_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2497\u001b[0m         \"\"\"\n\u001b[1;32m   2498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting data to be a DMatrix object, got: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM OOF or trained model predictions\n",
        "train_pred_lgb = lgb_model.predict(X_train)\n",
        "val_pred_lgb   = lgb_model.predict(X_val)\n",
        "\n",
        "# XGBoost (use numpy arrays directly)\n",
        "train_pred_xgb = xgb_model.predict(X_train)\n",
        "val_pred_xgb   = xgb_model.predict(X_val)\n",
        "\n",
        "# CatBoost\n",
        "train_pred_cat = cat_model.predict(X_train)\n",
        "val_pred_cat   = cat_model.predict(X_val)\n",
        "\n",
        "# Stack into meta-features\n",
        "X_meta_train = np.column_stack([train_pred_lgb, train_pred_xgb, train_pred_cat])\n",
        "X_meta_val   = np.column_stack([val_pred_lgb, val_pred_xgb, val_pred_cat])\n",
        "\n",
        "print(\"Meta-train shape:\", X_meta_train.shape)\n",
        "print(\"Meta-val shape:\", X_meta_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "FXRxleSJg4wL",
        "outputId": "0a09364b-7975-4aff-d25f-1866702201b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-794535895.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# XGBoost (use numpy arrays directly)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_pred_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mval_pred_xgb\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2497\u001b[0m         \"\"\"\n\u001b[1;32m   2498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting data to be a DMatrix object, got: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Create DMatrix\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dval   = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "# Set parameters\n",
        "params = {\n",
        "    \"objective\": \"reg:squarederror\",\n",
        "    \"tree_method\": \"gpu_hist\",\n",
        "    \"predictor\": \"gpu_predictor\",\n",
        "    \"learning_rate\": 0.05,\n",
        "    \"max_depth\": 8,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"random_state\": 42,\n",
        "    \"eval_metric\": \"rmse\"\n",
        "}\n",
        "\n",
        "# Train with early stopping\n",
        "model = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=1000,\n",
        "    evals=[(dtrain, \"train\"), (dval, \"val\")],\n",
        "    early_stopping_rounds=50,\n",
        "    verbose_eval=100\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "train_pred_xgb = model.predict(dtrain)\n",
        "val_pred_xgb   = model.predict(dval)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VlYOv_Hh8nf",
        "outputId": "6d474bcc-d95a-43f7-92c7-954da306e65a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:09:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [17:09:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"predictor\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-rmse:0.92719\tval-rmse:0.94189\n",
            "[100]\ttrain-rmse:0.57729\tval-rmse:0.76813\n",
            "[200]\ttrain-rmse:0.45752\tval-rmse:0.75093\n",
            "[300]\ttrain-rmse:0.37633\tval-rmse:0.74253\n",
            "[400]\ttrain-rmse:0.31498\tval-rmse:0.73699\n",
            "[500]\ttrain-rmse:0.26745\tval-rmse:0.73360\n",
            "[600]\ttrain-rmse:0.22606\tval-rmse:0.73075\n",
            "[700]\ttrain-rmse:0.19464\tval-rmse:0.72917\n",
            "[800]\ttrain-rmse:0.16756\tval-rmse:0.72777\n",
            "[900]\ttrain-rmse:0.14514\tval-rmse:0.72673\n",
            "[999]\ttrain-rmse:0.12671\tval-rmse:0.72594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [17:10:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£ Load all trained models\n",
        "# -----------------------------\n",
        "xgb_model = pickle.load(open(\"/content/xgb_model_gpu.pkl\", \"rb\"))\n",
        "lgb_model = pickle.load(open(\"/content/lgb_model_gpu.pkl\", \"rb\"))\n",
        "cat_model = cb.CatBoostRegressor()\n",
        "cat_model.load_model(\"/content/cat_model_gpu.cbm\")\n",
        "\n",
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ Get base model predictions\n",
        "# -----------------------------\n",
        "# assuming you already have X_train, X_val, y_train, y_val\n",
        "\n",
        "train_pred_xgb = xgb_model.predict(X_train)\n",
        "train_pred_lgb = lgb_model.predict(X_train)\n",
        "train_pred_cat = cat_model.predict(X_train)\n",
        "\n",
        "val_pred_xgb = xgb_model.predict(X_val)\n",
        "val_pred_lgb = lgb_model.predict(X_val)\n",
        "val_pred_cat = cat_model.predict(X_val)\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ Create new feature set (stacked)\n",
        "# -----------------------------\n",
        "X_train_stack = np.column_stack((train_pred_xgb, train_pred_lgb, train_pred_cat))\n",
        "X_val_stack = np.column_stack((val_pred_xgb, val_pred_lgb, val_pred_cat))\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ Train a meta-model\n",
        "# -----------------------------\n",
        "meta_model = Ridge(alpha=1.0)\n",
        "meta_model.fit(X_train_stack, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ Evaluate stacking performance\n",
        "# -----------------------------\n",
        "val_pred_stack = meta_model.predict(X_val_stack)\n",
        "\n",
        "rmse = mean_squared_error(y_val, val_pred_stack, squared=False)\n",
        "r2 = r2_score(y_val, val_pred_stack)\n",
        "\n",
        "print(f\"Stacked Model RMSE: {rmse:.4f}\")\n",
        "print(f\"Stacked Model R¬≤:   {r2:.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 6Ô∏è‚É£ (Optional) Save stacked model\n",
        "# -----------------------------\n",
        "joblib.dump(meta_model, \"stacked_meta_model.pkl\")\n",
        "print(\"‚úÖ Stacking completed and model saved as stacked_meta_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "d5e3Wpd1kUX7",
        "outputId": "1c4db809-bdeb-44d1-903d-5e7da1833180"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-660348530.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# assuming you already have X_train, X_val, y_train, y_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_pred_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mtrain_pred_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtrain_pred_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   2497\u001b[0m         \"\"\"\n\u001b[1;32m   2498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2499\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting data to be a DMatrix object, got: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2501\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Expecting data to be a DMatrix object, got: ', <class 'numpy.ndarray'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------- Step 0: Imports -------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ------------------------- Step 1: Load Features -------------------------\n",
        "# Load your precomputed embeddings\n",
        "train_text_embeddings = np.load('/content/drive/MyDrive/student_resource/embeddings/train_text_embeddings_75k.npy')\n",
        "train_image_embeddings = np.load('/content/drive/MyDrive/student_resource/embeddings/train_image_embeddings_75k.npy')\n",
        "\n",
        "# Extra features from DataFrame\n",
        "train_df['text_len'] = train_df['catalog_content'].apply(len)\n",
        "train_df['num_words'] = train_df['catalog_content'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Combine features\n",
        "X = np.concatenate([\n",
        "    train_text_embeddings,\n",
        "    train_image_embeddings,\n",
        "    train_df[['text_len','num_words']].values\n",
        "], axis=1)\n",
        "\n",
        "y = np.log1p(train_df['price'].values)  # log-transform for stability\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "\n",
        "# ------------------------- Step 2: Train/Validation Split -------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, \"Val shape:\", X_val.shape)\n",
        "\n",
        "# ------------------------- Step 3: LightGBM GPU Training -------------------------\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective='regression',\n",
        "    metric='rmse',\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.8,\n",
        "    bagging_freq=5,\n",
        "    n_estimators=1000,\n",
        "    device='gpu',          # GPU training\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "# Train with early stopping\n",
        "lgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    eval_metric='rmse',\n",
        "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
        ")\n",
        "\n",
        "# ------------------------- Step 4: Save Model -------------------------\n",
        "import joblib\n",
        "joblib.dump(lgb_model, \"lgb_model_single_fold.pkl\")\n",
        "print(\"‚úÖ LightGBM model trained and saved successfully!\")\n",
        "\n",
        "# ------------------------- Step 5: Predictions -------------------------\n",
        "train_pred = lgb_model.predict(X_train)\n",
        "val_pred   = lgb_model.predict(X_val)\n",
        "\n",
        "print(\"Training RMSE:\", np.sqrt(np.mean((train_pred - y_train)**2)))\n",
        "print(\"Validation RMSE:\", np.sqrt(np.mean((val_pred - y_val)**2)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axaLp40Bkl8w",
        "outputId": "73684144-4617-4aea-8ca9-34027c5c6542"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (75000, 1026)\n",
            "y shape: (75000,)\n",
            "Train shape: (60000, 1026) Val shape: (15000, 1026)\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[100]\tvalid_0's rmse: 0.790806\n",
            "[200]\tvalid_0's rmse: 0.768999\n",
            "[300]\tvalid_0's rmse: 0.757248\n",
            "[400]\tvalid_0's rmse: 0.749737\n",
            "[500]\tvalid_0's rmse: 0.745122\n",
            "[600]\tvalid_0's rmse: 0.741246\n",
            "[700]\tvalid_0's rmse: 0.738432\n",
            "[800]\tvalid_0's rmse: 0.736553\n",
            "[900]\tvalid_0's rmse: 0.734807\n",
            "[1000]\tvalid_0's rmse: 0.73348\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[995]\tvalid_0's rmse: 0.73347\n",
            "‚úÖ LightGBM model trained and saved successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RMSE: 0.46554230544162095\n",
            "Validation RMSE: 0.7334695495685832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------- Step 0: Imports -------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# ------------------------- Step 1: Load Test Features -------------------------\n",
        "# Load your precomputed test embeddings\n",
        "test_text_embeddings = np.load('/content/drive/MyDrive/student_resource/embeddings/train_image_embeddings_75k.npy')\n",
        "test_image_embeddings = np.load('/content/drive/MyDrive/student_resource/embeddings/train_image_embeddings_75k.npy')\n",
        "\n",
        "# Extra features from test DataFrame\n",
        "test_df['text_len'] = test_df['catalog_content'].apply(len)\n",
        "test_df['num_words'] = test_df['catalog_content'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Combine features\n",
        "X_test = np.concatenate([\n",
        "    test_text_embeddings,\n",
        "    test_image_embeddings,\n",
        "    test_df[['text_len','num_words']].values\n",
        "], axis=1)\n",
        "\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# ------------------------- Step 2: Load Trained LightGBM Model -------------------------\n",
        "lgb_model = joblib.load(\"lgb_model_single_fold.pkl\")\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "# ------------------------- Step 3: Predict -------------------------\n",
        "test_pred_log = lgb_model.predict(X_test)       # predictions in log space\n",
        "test_pred = np.expm1(test_pred_log)            # revert log transform\n",
        "\n",
        "# ------------------------- Step 4: Prepare Submission -------------------------\n",
        "submission = pd.DataFrame({\n",
        "    'item_id': test_df['item_id'],   # or the appropriate ID column in your dataset\n",
        "    'predicted_price': test_pred\n",
        "})\n",
        "\n",
        "# Save CSV\n",
        "submission.to_csv('submission_lgb_single_fold.csv', index=False)\n",
        "print(\"‚úÖ Submission CSV saved: submission_lgb_single_fold.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "XLPkcav9nJUl",
        "outputId": "feb78b00-452d-40ba-a1c1-3e90ab645dfd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (75000, 1026)\n",
            "‚úÖ Model loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'item_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'item_id'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3101463432.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# ------------------------- Step 4: Prepare Submission -------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m submission = pd.DataFrame({\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;34m'item_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# or the appropriate ID column in your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;34m'predicted_price'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m })\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'item_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSINdyYDoFWH",
        "outputId": "868583f6-e223-46e3-9108-ed7e5c72c18c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['sample_id', 'catalog_content', 'image_link', 'text_len', 'num_words'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load test embeddings\n",
        "X_test = np.load('/content/test_embeddings.npy')  # update path if needed\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# Load trained LightGBM model\n",
        "lgb_model = joblib.load('/content/lgb_model_single_fold.pkl')  # update path\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "# Make predictions\n",
        "test_pred_log = lgb_model.predict(X_test)\n",
        "test_pred = np.expm1(test_pred_log)  # inverse of log1p\n",
        "\n",
        "# Prepare submission\n",
        "submission = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],  # use the correct ID column\n",
        "    'predicted_price': test_pred\n",
        "})\n",
        "\n",
        "# Save CSV\n",
        "submission.to_csv('submission_lgb_single_fold.csv', index=False)\n",
        "print(\"‚úÖ Submission CSV saved!\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load test embeddings\n",
        "X_test = np.load('/content/test_embeddings.npy')  # update path if needed\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# Load trained LightGBM model\n",
        "lgb_model = joblib.load('/content/lgb_model_single_fold.pkl')  # update path\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "# Make predictions\n",
        "test_pred_log = lgb_model.predict(X_test)\n",
        "test_pred = np.expm1(test_pred_log)  # inverse of log1p\n",
        "\n",
        "# Prepare submission\n",
        "submission = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],  # use the correct ID column\n",
        "    'predicted_price': test_pred\n",
        "})\n",
        "\n",
        "# Save CSV\n",
        "submission.to_csv('submission_lgb_single_fold.csv', index=False)\n",
        "print(\"‚úÖ Submission¬†CSV¬†saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "w_j3VjARobL6",
        "outputId": "0e64b76b-ebb7-4605-d32f-a633a3472c15"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/test_embeddings.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1464232086.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load test embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test_embeddings.npy'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update path if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_test shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/test_embeddings.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load embeddings\n",
        "test_text_embeddings = np.load('/content/test_image_embeddings_75k.npy')\n",
        "test_image_embeddings = np.load('/content/test_text_embeddings_75k.npy')\n",
        "\n",
        "# Extra features\n",
        "test_df['text_len'] = test_df['catalog_content'].apply(len)\n",
        "test_df['num_words'] = test_df['catalog_content'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Combine all features exactly like training\n",
        "X_test = np.concatenate([\n",
        "    test_text_embeddings,\n",
        "    test_image_embeddings,\n",
        "    test_df[['text_len', 'num_words']].values\n",
        "], axis=1)\n",
        "\n",
        "print(\"X_test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taS7iKtcqYuv",
        "outputId": "32e7ef3a-9570-4111-c07c-f98fe0fc82a4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (75000, 1026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# ------------------- Step 1: Load test embeddings -------------------\n",
        "test_text_embeddings = np.load('/content/test_text_embeddings_75k.npy')   # text embeddings\n",
        "test_image_embeddings = np.load('/content/test_image_embeddings_75k.npy') # image embeddings\n",
        "\n",
        "# ------------------- Step 2: Prepare extra features -------------------\n",
        "# Make sure test_df is already loaded\n",
        "test_df['text_len'] = test_df['catalog_content'].apply(len)\n",
        "test_df['num_words'] = test_df['catalog_content'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# ------------------- Step 3: Combine features -------------------\n",
        "X_test = np.concatenate([\n",
        "    test_text_embeddings,\n",
        "    test_image_embeddings,\n",
        "    test_df[['text_len', 'num_words']].values\n",
        "], axis=1)\n",
        "\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# ------------------- Step 4: Load trained LightGBM model -------------------\n",
        "lgb_model = joblib.load('/content/drive/MyDrive/student_resource/lgb_model_single_fold.pkl')  # replace with your saved model path\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "# ------------------- Step 5: Make predictions -------------------\n",
        "test_pred_log = lgb_model.predict(X_test)    # predictions are in log1p scale\n",
        "test_pred = np.expm1(test_pred_log)          # inverse of log1p\n",
        "\n",
        "# ------------------- Step 6: Prepare submission -------------------\n",
        "submission = pd.DataFrame({\n",
        "    'sample_id': test_df['sample_id'],  # correct ID column\n",
        "    'predicted_price': test_pred\n",
        "})\n",
        "\n",
        "# ------------------- Step 7: Save CSV -------------------\n",
        "submission.to_csv('submission_lgb_single_fold_final.csv', index=False)\n",
        "print(\"‚úÖ Submission¬†CSV¬†saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BKJsIp4quf-",
        "outputId": "90ec38a0-cbe8-4951-964b-c9f2d2116d76"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (75000, 1026)\n",
            "‚úÖ Model loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Submission¬†CSV¬†saved!\n"
          ]
        }
      ]
    }
  ]
}